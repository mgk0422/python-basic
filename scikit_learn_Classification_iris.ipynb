{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scikit_learn_Classification_iris",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNmbptbyQdWp6u+qc/Q8ekM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgk0422/python-basic/blob/master/scikit_learn_Classification_iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8T_xvECEThWS"
      },
      "source": [
        "# 사이킷런_ 머신러닝 라이브러리 중 가장많이 사용하는 라이브러리\r\n",
        "# 가장쉽고 효율적\r\n",
        "# 분류는 대표적인 지도학습 방법\r\n",
        "# 지도학습은 명확한 정답이 주어진 데이터를 먼저 학습 한 뒤 미지의 정답을 예측하는 방식\r\n",
        "from sklearn.datasets import load_iris #sklearn.datasets은 사이킷런에서 자체적으로 제공하는 데이터 세트를 생성하는 모듈의 모임\r\n",
        "from sklearn.tree import DecisionTreeClassifier #sklearn.tree은 트리기반 ML알고리즘을 구현한 클래스의 모임\r\n",
        "from sklearn.model_selection import train_test_split #sklearn.model_selection은 학습데이터와 검증데이터, 예측데이터로 분리하거나 최적의 하이퍼 파라미터로 평가하기위해"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMqIhokDZwLD"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import glob\r\n",
        "import sys\r\n",
        "from openpyxl import load_workbook\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9k_KYI8YLJV"
      },
      "source": [
        "import sklearn\r\n",
        "import pandas as pd\r\n",
        "iris=load_iris()\r\n",
        "\r\n",
        "#iris.data는 iris 데이터 세트에서 피처만(feature)만으로 된 데이터 numpy로 가지고있습니다.\r\n",
        "iris_data=iris.data\r\n",
        "# iris.target은 불꽃 데이터 세트에서 레이블(결정 값)데이터를 numpy로 가지고 있다.\r\n",
        "iris_label=iris.target\r\n",
        "\r\n",
        "print('iris target 값:',iris_label)\r\n",
        "print('iris target 명',iris.target_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSJ1bg6gZvtu"
      },
      "source": [
        "iris_df=pd.DataFrame(iris_data,columns=iris.feature_names)\r\n",
        "iris_df['label']=iris.target\r\n",
        "iris_df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js_b4W-8Y-Uk"
      },
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(iris_data,iris_label,test_size=0.2,random_state=11)\r\n",
        "#첫번째 피라미터 iris_data 피처데이터세트, 두번째 iris_label 레이블데이터세트, random_state는 호출할때마다 같은 학습/테스트 용 데이터 세트를 생성하기 위해 주어지는 난수 발생하는 값"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBMIgC4Xw0ot"
      },
      "source": [
        "# DecisionTreeClassifier 객체 생성\r\n",
        "df_clf=DecisionTreeClassifier(random_state=11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTol1uQnw-Zf"
      },
      "source": [
        "# 학습 수행\r\n",
        "df_clf.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_Wlsk-rxI68"
      },
      "source": [
        "# 학습이 완료된 객체에서 테스트 데이터 세트를 예측 수행\r\n",
        "pred=df_clf.predict(X_test) #정확도는 예측 결과가 실제 레이블 값과 얼마나 정확하게 맞는지 평가하는 지표"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9_TkvKrxvaT"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\r\n",
        "accuracy_score(y_test,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCNiZ5Rcx8Vz"
      },
      "source": [
        "# 분류 : 1. 데이터세트분리, 2.모델학습 , 3.예측수행 , 4.평가"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNDjPJKQyQye"
      },
      "source": [
        "# 학습/테스트 데이터 세트 분리 - train_test_split()\r\n",
        "from sklearn.datasets import load_iris\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "iris=load_iris()\r\n",
        "df_clf=DecisionTreeClassifier()\r\n",
        "train_data=iris.data\r\n",
        "train_label=iris.target\r\n",
        "df_clf.fit(train_data,train_label)\r\n",
        "\r\n",
        "pred=df_clf.predict(train_data)\r\n",
        "accuracy_score(train_label,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOYHMHM30dZS"
      },
      "source": [
        "#1.0이 나오는 이유 : 이미 학습한 학습 데이터 세트를 기반으로 예측했기때문"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Knh5v2Ht05oV"
      },
      "source": [
        "# 학습/테스트 데이터 세트 분리 - train_test_split()\r\n",
        "from sklearn.datasets import load_iris\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "df_clf=DecisionTreeClassifier()\r\n",
        "iris_data=load_iris()\r\n",
        "\r\n",
        "X_train,X_test,y_train,y_test=train_test_split(iris_data.data,iris_data.target,test_size=0.3,random_state=121)\r\n",
        "df_clf.fit(X_train,y_train) #학습\r\n",
        "pred=df_clf.predict(X_test) #예측\r\n",
        "accuracy_score(y_test,pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21yohf1F1qg4"
      },
      "source": [
        "# 알고리즘을 학습시키는 학습데이터와 이에 대한 예측 성능을 평가하기 위한 별도의 테스트가 필요함\r\n",
        "# 과적합에 취약한 약점을 가질수 있음\r\n",
        "# 과적합이란 모델이 학습데이터에만 과도하게 최적화되어, 실제 예측을 다른 데이터로 수행할 경우에는 예측 성능이 과도하게 떨어지는것을 말함"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDCGSQwf2i-6"
      },
      "source": [
        "#### 교차검증\r\n",
        "\r\n",
        "*   데이터 편중을 막기 위해 별도의 여러 세트로 구성된 학습 데이터 세트와 검증 데이터 세트에서 학습과 평가를 수행하는 것\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJxd_QvV2ecf"
      },
      "source": [
        "# k폴드 교차 검증\r\n",
        "# k개의 데이터 폴드 세트를 만들어서 k번만큼 각 폴트 세트에 학습과 검증 평가를 반복적으로 수행하는 방법\r\n",
        "# KFold , stratifiedKFold 클래스 제공"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FpmH5m42zRD"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "iris=load_iris()\r\n",
        "features=iris.data\r\n",
        "label=iris.target\r\n",
        "df_clf=DecisionTreeClassifier(random_state=156)\r\n",
        "\r\n",
        "kfold=KFold(n_splits=5)\r\n",
        "cv_accuracy=[]\r\n",
        "\r\n",
        "n_iter=0\r\n",
        "\r\n",
        "for train_index, test_index in kfold.split(features):\r\n",
        "    X_train,X_test=features[train_index],features[test_index]\r\n",
        "    y_train,y_test=label[train_index],label[test_index]\r\n",
        "    df_clf.fit(X_train,y_train)\r\n",
        "    pred=df_clf.predict(X_test)\r\n",
        "    n_iter+=1\r\n",
        "    accuracy=np.round(accuracy_score(y_test,pred),4)\r\n",
        "    cv_accuracy.append(accuracy)\r\n",
        "print(cv_accuracy)\r\n",
        "print(np.mean(cv_accuracy))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFpHGnxR6FpS"
      },
      "source": [
        "#Stratified K폴드\r\n",
        "# 불균형한 분포도를 가진 레이블 데이터 집합을 위한 K폴드 방식\r\n",
        "# 불균형한 분포도를 가진 레이블 데이터 집합은 특정 레이블 값이 특이하게 많거나 매우 적어서 분푸가 한쪽으로 치우치는 경우\r\n",
        "import pandas as pd\r\n",
        "iris=load_iris()\r\n",
        "iris_df=pd.DataFrame(iris.data,columns=iris.feature_names)\r\n",
        "iris_df['label']=iris.target\r\n",
        "iris_df['label'].value_counts() #각 레이블의 갯수"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5jDqvh5W8N5"
      },
      "source": [
        "kfold=KFold(n_splits=3)\r\n",
        "n_iter=0\r\n",
        "for train_index,test_index in kfold.split(iris_df):\r\n",
        "    n_iter+=1\r\n",
        "    label_train=iris_df['label'].iloc[train_index]\r\n",
        "    label_test=iris_df['label'].iloc[test_index]\r\n",
        "print('학습 레이블 데이터 분포',label_train.value_counts())\r\n",
        "print('검증 레이블 데이터 분포',label_test.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVM98CF6Xo5i"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\r\n",
        "skf=StratifiedKFold(n_splits=3)\r\n",
        "skfold=StratifiedKFold(n_splits=3)\r\n",
        "n_iter=0\r\n",
        "cv_accuracy=[]\r\n",
        "for train_index,test_index in skfold.split(features,label):\r\n",
        "    X_train,X_test=features[train_index],features[test_index]\r\n",
        "    y_train,y_test=label[train_index],label[test_index]\r\n",
        "    df_clf.fit(X_train,y_train)\r\n",
        "    pred=df_clf.predict(X_test)\r\n",
        "    n_iter+=1\r\n",
        "    accuracy=np.round(accuracy_score(y_test,pred),4)\r\n",
        "    train_size=X_train.shape[0]\r\n",
        "    test_size=X_test.shape[0]\r\n",
        "    print('###교차검증정확도:{1},학습데이터크기:{2},검증데이터크기:{3}'.format(n_iter,accuracy,train_size,test_size))\r\n",
        "    print('###검증세트인덱스{1}'.format(n_iter,test_index))\r\n",
        "    cv_accuracy.append(accuracy)\r\n",
        "print('교차검증별정확도',cv_accuracy)\r\n",
        "print('교차검증별평균정확도',np.mean(cv_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJ8_n8YFYujs"
      },
      "source": [
        "# Stratified K폴드의 경우 원본 데이터의 레이블 분포도 특성을 반영한 학습 및 검증 데이터 세트를 만들 수  있으므로 왜곡된 레이블 데이터 세트에서는 반드시\r\n",
        "# Stratified k폴드를 이용해 교차검증을 해야한다.\r\n",
        "# 회귀에서는 Stratified k폴드가 지원되지않음 왜? 회귀의 결정값은 연속된 숫자값이기 때문이다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGrgca9pbw0D"
      },
      "source": [
        "#교차검증을 간편하게 -cross_val_score()\r\n",
        "# cross_val_score(estimator,X,y=None,scoring=None,cv=None,n_jobs=1,verbose=0,fit_params=None) ## estimator,X,y,scoring,cv가 주요 파라미터\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.model_selection import cross_val_score,cross_validate\r\n",
        "from sklearn.datasets import load_iris\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "iris_data=load_iris()\r\n",
        "df_clf=DecisionTreeClassifier(random_state=156)\r\n",
        "\r\n",
        "data=iris_data.data\r\n",
        "label=iris_data.target\r\n",
        "#성능지료 정확도, 교차 검증 세트는 3개\r\n",
        "scores=cross_val_score(df_clf,data,label,scoring='accuracy',cv=3)\r\n",
        "print('교차검증별정확도:',np.round(scores,4))\r\n",
        "print('평균검증정확도:',np.round(np.mean(scores),4))\r\n",
        "\r\n",
        "#cross_val_score()가 내부적으로 StratifiedKFold를 이용한다"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma3lKboed0YS"
      },
      "source": [
        "# GridSearchCV-교차검증과 최적의 파라미터 튜닝을 한번에\r\n",
        "# 하이퍼파라미터는 머신러닝 알고리즘을 구성하는 주요구성 알고리즘\r\n",
        "# GridSearchCV는 교차 검증을 기반으로 하이퍼 파라미터의 최적 값을 찾게 해준다.\r\n",
        "grid_parameters={'max_depth':[1,2,3], \r\n",
        "                 'min_sample_split':[2,3]\r\n",
        "                 }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dQAmjqMgjIA"
      },
      "source": [
        "from sklearn.datasets import load_iris\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "\r\n",
        "# 데이터를 로딩하고 학습데이타와 테스트 데이터 분리\r\n",
        "iris = load_iris()\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, \r\n",
        "                                                    test_size=0.2, random_state=121)\r\n",
        "dtree = DecisionTreeClassifier()\r\n",
        "\r\n",
        "### parameter 들을 dictionary 형태로 설정\r\n",
        "parameters = {'max_depth':[1,2,3], 'min_samples_split':[2,3]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdu8SdPUmxv9"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "# param_grid의 하이퍼 파라미터들을 3개의 train, test set fold 로 나누어서 테스트 수행 설정.  \r\n",
        "### refit=True 가 default 임. True이면 가장 좋은 파라미터 설정으로 재 학습 시킴.  \r\n",
        "grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=3, refit=True)\r\n",
        "\r\n",
        "# 붓꽃 Train 데이터로 param_grid의 하이퍼 파라미터들을 순차적으로 학습/평가 .\r\n",
        "grid_dtree.fit(X_train, y_train)\r\n",
        "\r\n",
        "# GridSearchCV 결과 추출하여 DataFrame으로 변환\r\n",
        "scores_df = pd.DataFrame(grid_dtree.cv_results_)\r\n",
        "scores_df[['params', 'mean_test_score', 'rank_test_score', \\\r\n",
        "           'split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEK1VnKwm1em"
      },
      "source": [
        "print('GridSearchCV 최적 파라미터:', grid_dtree.best_params_)\r\n",
        "print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dtree.best_score_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYOPEEp9m-Jj"
      },
      "source": [
        "# GridSearchCV의 refit으로 이미 학습이 된 estimator 반환\r\n",
        "estimator = grid_dtree.best_estimator_\r\n",
        "\r\n",
        "# GridSearchCV의 best_estimator_는 이미 최적 하이퍼 파라미터로 학습이 됨\r\n",
        "pred = estimator.predict(X_test)\r\n",
        "print('테스트 데이터 세트 정확도: {0:.4f}'.format(accuracy_score(y_test,pred)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BBgEP2FnBrN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}