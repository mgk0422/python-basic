{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hyper_Parameter_양파_시장",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO01hymqulreZ1lAx48IFGK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgk0422/python-basic/blob/master/hyper_Parameter_%EC%96%91%ED%8C%8C_%EC%8B%9C%EC%9E%A5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ght0hmsAgAED"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGWsvopWmUQD"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgyAPv-nmUQD"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZAfg6M9mUQD"
      },
      "source": [
        "양파"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOYfauNmmUQD"
      },
      "source": [
        "dataset = pd.read_excel('/content/양파_시장.xlsx')\n",
        "# dataset = pd.merge(dataset, wholesale, how='left', on='일자' )\n",
        "# dataset.head()\n",
        "# dataset = pd.read_excel('/content/무_특_반입_경락_시장_날씨_Holy_유가.xlsx')\n",
        "# dataset = dataset.drop(['일자','품목명','품목코드','유무','평균 5cm 지중온도(°C)','평균 지면온도(°C)','최고기온(°C)','합계 일조시간(hr)','최저기온(°C)'], axis=1)\n",
        "# dataset = dataset.drop(['일자', '최대 풍속(m/s)',\t'평균 풍속(m/s)',\t'평균 상대습도(%)',\t'합계 일조시간(hr)',\t'평균 지면온도(°C)',\t'평균 5cm 지중온도(°C)', '여부'], axis=1)\n",
        "# dataset = dataset[['도매가격', '100g가격', '유가 전국평균가격', '평균 풍속(m/s)', '여부', '최고기온(°C)', '평균 지면온도(°C)', '평균 5cm 지중온도(°C)', '일강수량(mm)', '반입량']]\n",
        "# dataset = dataset.drop(['일자','Unnamed: 0'], axis=1)\n",
        "#dataset = dataset.drop(['일자'], axis=1)\n",
        "dataset = dataset.dropna()\n",
        "dataset.head()\n",
        "# dataset.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LCY-408mUQD"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-85ANPnmUQD"
      },
      "source": [
        "y_target = dataset['가격']\n",
        "X_data = dataset.drop(['가격'], axis=1, inplace=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zNFlUZXmUQD"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_target, test_size=0.15, random_state=140)\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mc2h5wGpmUQD"
      },
      "source": [
        "# 검증해주는 함수\n",
        "def get_model_cv_prediction(model, X_data, y_target):\n",
        "  neg_mse_scores=cross_val_score(model, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 5)\n",
        "  rmse_scores = np.sqrt(-1 * neg_mse_scores)\n",
        "  avg_rmse = np.mean(rmse_scores)\n",
        "  model.fit(X_data, y_target)\n",
        "  score = model.score(X_data, y_target)\n",
        "  kf_cv_scores = cross_val_score(model, X_data, y_target)\n",
        "  print('#### ', model.__class__.__name__, ' ####')\n",
        "  print(' 5 교차 검증의 평균 RMSE : {0:.3f} '.format(avg_rmse))\n",
        "  print('score : ', score)\n",
        "  print(\"K-fold CV scores : {}\" .format(kf_cv_scores))\n",
        "  print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mwPWx9jmUQD"
      },
      "source": [
        "## XGBoost Regressor 하이퍼파라미터\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WybAl1BbmUQD"
      },
      "source": [
        "# XGBoost Hypter Parameter Tuning\n",
        "def XGBhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.03, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'min_child_weight': [1, 3, 5],\n",
        "        'subsample': [0.5, 0.7],\n",
        "        'colsample_bytree': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500],\n",
        "        'objective': ['reg:squarederror'],\n",
        "        'gamma' : [0.1, 0.2, 0.3, 0.4],\n",
        "\n",
        "    }\n",
        "\n",
        "    xgb_model = XGBRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = xgb_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def RFRhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 1000],\n",
        "    \n",
        "    }\n",
        "\n",
        "    rf_model = RandomForestRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = rf_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def LGBMhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.03, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'min_child_samples' : [10, 20, 30],\n",
        "        'subsample' : [0.5, 0.7],\n",
        "        'colsample_bytree': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500],\n",
        "        'objective': ['regression'],\n",
        "        'gamma' : [0.1, 0.2, 0.3],\n",
        "        'num_leaves' : [6, 8, 10]\n",
        "\n",
        "    }\n",
        "\n",
        "    lgbm = LGBMRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = lgbm,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def GBRhyperParameterTuning(X_train, y_train):\n",
        "    \n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'subsample': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500]\n",
        "\n",
        "    }\n",
        "\n",
        "    gb_model = GradientBoostingRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = gb_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xjD6MPsmUQE"
      },
      "source": [
        "xgb_parameter = XGBhyperParameterTuning(X_train, y_train)\n",
        "xgb_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPThK-PDmUQE"
      },
      "source": [
        "rf_parameter = RFRhyperParameterTuning(X_train, y_train)\n",
        "rf_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGThKhOqmUQE"
      },
      "source": [
        "lgbm_parameter = LGBMhyperParameterTuning(X_train, y_train)\n",
        "lgbm_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRmNzlcemUQE"
      },
      "source": [
        "\n",
        "#rf_parameter = RFRhyperParameterTuning(X_train, y_train)\n",
        "#rf_parameter\n",
        "\n",
        "gbr_parameter= GBRhyperParameterTuning(X_train, y_train)\n",
        "gbr_parameter\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTzlxpgqmUQE"
      },
      "source": [
        "# 모델 생성 및 예측\n",
        "xgb_reg = XGBRegressor(colsample_bytree = 0.5, \n",
        "                       gamma = 0.1,\n",
        "                       learning_rate = 0.01,\n",
        "                       max_depth = 3,\n",
        "                       min_child_weight = 5,\n",
        "                       n_estimators = 500,\n",
        "                       objective = 'reg:squarederror',\n",
        "                       subsample = 0.5)\n",
        "\n",
        "rf_reg = RandomForestRegressor(random_state=0, \n",
        "                               bootstrap = [True],\n",
        "                               max_depth = 7,\n",
        "                               max_features = 2,\n",
        "                               min_samples_leaf = 5,\n",
        "                               min_samples_split = 12,\n",
        "                               n_estimators = 100\n",
        "                               )\n",
        "\n",
        "lgb_reg = LGBMRegressor(colsample_bytree = 0.5,\n",
        "                        gamma = 0.1,\n",
        "                        learning_rate = 0.01,\n",
        "                        max_depth = 5,\n",
        "                        min_child_samples = 10,\n",
        "                        n_estimators = 200,\n",
        "                        num_leaves =6,\n",
        "                        objective = 'regression',\n",
        "                        subsample = 0.5)\n",
        "\n",
        "gb_reg = GradientBoostingRegressor(random_state=0, \n",
        "                                   learning_rate=0.01,\n",
        "                                   max_depth=3,\n",
        "                                   n_estimators=200,\n",
        "                                   subsample=0.5\n",
        "                                   )\n",
        "\n",
        "models = [lgb_reg, rf_reg, gb_reg, xgb_reg, lgb_reg]\n",
        "\n",
        "for model in models:\n",
        "  get_model_cv_prediction(model, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU9g_knImUQE"
      },
      "source": [
        "ypred = rf_reg.predict(X_test)\n",
        "mse = mean_squared_error(y_test, ypred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsXw96ZTmUQE"
      },
      "source": [
        "x_ax = range(len(y_test))\n",
        "plt.plot(x_ax, y_test, label=\"Original Price\")\n",
        "plt.plot(x_ax, ypred, label=\"Predicted Price\")\n",
        "plt.title(\"Price Prediction\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72I0XwsmmUQE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN-B8UOCmUQE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5d-dxnymUQE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O5OKOW_mUQE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxeS0g6rmW4F"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okArfiXBmW4G"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ9mgJWimW4G"
      },
      "source": [
        "#배추"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrwOtpa4mW4G"
      },
      "source": [
        "dataset = pd.read_excel('/content/배추_시장.xlsx')\n",
        "# dataset = pd.merge(dataset, wholesale, how='left', on='일자' )\n",
        "# dataset.head()\n",
        "# dataset = pd.read_excel('/content/무_특_반입_경락_시장_날씨_Holy_유가.xlsx')\n",
        "# dataset = dataset.drop(['일자','품목명','품목코드','유무','평균 5cm 지중온도(°C)','평균 지면온도(°C)','최고기온(°C)','합계 일조시간(hr)','최저기온(°C)'], axis=1)\n",
        "# dataset = dataset.drop(['일자', '최대 풍속(m/s)',\t'평균 풍속(m/s)',\t'평균 상대습도(%)',\t'합계 일조시간(hr)',\t'평균 지면온도(°C)',\t'평균 5cm 지중온도(°C)', '여부'], axis=1)\n",
        "# dataset = dataset[['도매가격', '100g가격', '유가 전국평균가격', '평균 풍속(m/s)', '여부', '최고기온(°C)', '평균 지면온도(°C)', '평균 5cm 지중온도(°C)', '일강수량(mm)', '반입량']]\n",
        "# dataset = dataset.drop(['일자','Unnamed: 0'], axis=1)\n",
        "#dataset = dataset.drop(['일자'], axis=1)\n",
        "dataset = dataset.dropna()\n",
        "dataset.head()\n",
        "# dataset.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBmjE1_lmW4G"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwCnIEkFmW4G"
      },
      "source": [
        "y_target = dataset['가격']\n",
        "X_data = dataset.drop(['가격'], axis=1, inplace=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0Clbel-mW4G"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_target, test_size=0.15, random_state=140)\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMXrrKxymW4G"
      },
      "source": [
        "# 검증해주는 함수\n",
        "def get_model_cv_prediction(model, X_data, y_target):\n",
        "  neg_mse_scores=cross_val_score(model, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 5)\n",
        "  rmse_scores = np.sqrt(-1 * neg_mse_scores)\n",
        "  avg_rmse = np.mean(rmse_scores)\n",
        "  model.fit(X_data, y_target)\n",
        "  score = model.score(X_data, y_target)\n",
        "  kf_cv_scores = cross_val_score(model, X_data, y_target)\n",
        "  print('#### ', model.__class__.__name__, ' ####')\n",
        "  print(' 5 교차 검증의 평균 RMSE : {0:.3f} '.format(avg_rmse))\n",
        "  print('score : ', score)\n",
        "  print(\"K-fold CV scores : {}\" .format(kf_cv_scores))\n",
        "  print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qtGknXDmW4G"
      },
      "source": [
        "## XGBoost Regressor 하이퍼파라미터\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEeVmceYmW4G"
      },
      "source": [
        "# XGBoost Hypter Parameter Tuning\n",
        "def XGBhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.03, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'min_child_weight': [1, 3, 5],\n",
        "        'subsample': [0.5, 0.7],\n",
        "        'colsample_bytree': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500],\n",
        "        'objective': ['reg:squarederror'],\n",
        "        'gamma' : [0.1, 0.2, 0.3, 0.4],\n",
        "\n",
        "    }\n",
        "\n",
        "    xgb_model = XGBRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = xgb_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def RFRhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 1000],\n",
        "    \n",
        "    }\n",
        "\n",
        "    rf_model = RandomForestRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = rf_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def LGBMhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.03, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'min_child_samples' : [10, 20, 30],\n",
        "        'subsample' : [0.5, 0.7],\n",
        "        'colsample_bytree': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500],\n",
        "        'objective': ['regression'],\n",
        "        'gamma' : [0.1, 0.2, 0.3],\n",
        "        'num_leaves' : [6, 8, 10]\n",
        "\n",
        "    }\n",
        "\n",
        "    lgbm = LGBMRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = lgbm,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def GBRhyperParameterTuning(X_train, y_train):\n",
        "    \n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'subsample': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500]\n",
        "\n",
        "    }\n",
        "\n",
        "    gb_model = GradientBoostingRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = gb_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDvcd12xmW4G"
      },
      "source": [
        "xgb_parameter = XGBhyperParameterTuning(X_train, y_train)\n",
        "xgb_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPX9Ok-smW4G"
      },
      "source": [
        "rf_parameter = RFRhyperParameterTuning(X_train, y_train)\n",
        "rf_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzxn6Tl8mW4G"
      },
      "source": [
        "lgbm_parameter = LGBMhyperParameterTuning(X_train, y_train)\n",
        "lgbm_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5I7Wc3HmW4G"
      },
      "source": [
        "\n",
        "#rf_parameter = RFRhyperParameterTuning(X_train, y_train)\n",
        "#rf_parameter\n",
        "\n",
        "gbr_parameter= GBRhyperParameterTuning(X_train, y_train)\n",
        "gbr_parameter\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktoWArkfmW4G"
      },
      "source": [
        "# 모델 생성 및 예측\n",
        "xgb_reg = XGBRegressor(colsample_bytree = 0.7, \n",
        "                       gamma = 0.2,\n",
        "                       learning_rate = 0.1,\n",
        "                       max_depth = 5,\n",
        "                       min_child_weight = 1,\n",
        "                       n_estimators = 500,\n",
        "                       objective = 'reg:squarederror',\n",
        "                       subsample = 0.7)\n",
        "\n",
        "rf_reg = RandomForestRegressor(random_state=0, \n",
        "                               bootstrap = [True],\n",
        "                               max_depth = 10,\n",
        "                               max_features = 3,\n",
        "                               min_samples_leaf = 3,\n",
        "                               min_samples_split = 8,\n",
        "                               n_estimators = 100\n",
        "                               )\n",
        "\n",
        "lgb_reg = LGBMRegressor(colsample_bytree = 0.7,\n",
        "                        gamma = 0.1,\n",
        "                        learning_rate = 0.03,\n",
        "                        max_depth = 7,\n",
        "                        min_child_samples = 10,\n",
        "                        n_estimators = 200,\n",
        "                        num_leaves =8,\n",
        "                        objective = 'regression',\n",
        "                        subsample = 0.5)\n",
        "\n",
        "gb_reg = GradientBoostingRegressor(random_state=0, \n",
        "                                   learning_rate=0.1,\n",
        "                                   max_depth=3,\n",
        "                                   n_estimators=200,\n",
        "                                   subsample=0.5\n",
        "                                   )\n",
        "\n",
        "models = [lgb_reg, rf_reg, gb_reg, xgb_reg, lgb_reg]\n",
        "\n",
        "for model in models:\n",
        "  get_model_cv_prediction(model, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB0hWLwqmW4G"
      },
      "source": [
        "ypred = rf_reg.predict(X_test)\n",
        "mse = mean_squared_error(y_test, ypred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftobhFMvmW4G"
      },
      "source": [
        "x_ax = range(len(y_test))\n",
        "plt.plot(x_ax, y_test, label=\"Original Price\")\n",
        "plt.plot(x_ax, ypred, label=\"Predicted Price\")\n",
        "plt.title(\"Price Prediction\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvyQ1LdQmW4G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHOaCjA_mW4G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHiPloixmW4G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aq9XxGUmW4G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfZnv2kumXb0"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score, train_test_split, KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf8htKzAmXb0"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii6_OhzSmXb0"
      },
      "source": [
        "#배추"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoVqgsdmmXb0"
      },
      "source": [
        "dataset = pd.read_excel('/content/배추_시장.xlsx')\n",
        "# dataset = pd.merge(dataset, wholesale, how='left', on='일자' )\n",
        "# dataset.head()\n",
        "# dataset = pd.read_excel('/content/무_특_반입_경락_시장_날씨_Holy_유가.xlsx')\n",
        "# dataset = dataset.drop(['일자','품목명','품목코드','유무','평균 5cm 지중온도(°C)','평균 지면온도(°C)','최고기온(°C)','합계 일조시간(hr)','최저기온(°C)'], axis=1)\n",
        "# dataset = dataset.drop(['일자', '최대 풍속(m/s)',\t'평균 풍속(m/s)',\t'평균 상대습도(%)',\t'합계 일조시간(hr)',\t'평균 지면온도(°C)',\t'평균 5cm 지중온도(°C)', '여부'], axis=1)\n",
        "# dataset = dataset[['도매가격', '100g가격', '유가 전국평균가격', '평균 풍속(m/s)', '여부', '최고기온(°C)', '평균 지면온도(°C)', '평균 5cm 지중온도(°C)', '일강수량(mm)', '반입량']]\n",
        "# dataset = dataset.drop(['일자','Unnamed: 0'], axis=1)\n",
        "#dataset = dataset.drop(['일자'], axis=1)\n",
        "dataset = dataset.dropna()\n",
        "dataset.head()\n",
        "# dataset.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOjnVRFbmXb0"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAkS3uqcmXb0"
      },
      "source": [
        "y_target = dataset['가격']\n",
        "X_data = dataset.drop(['가격'], axis=1, inplace=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9gs15q3mXb0"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_target, test_size=0.15, random_state=140)\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBtcc-_DmXb0"
      },
      "source": [
        "# 검증해주는 함수\n",
        "def get_model_cv_prediction(model, X_data, y_target):\n",
        "  neg_mse_scores=cross_val_score(model, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 5)\n",
        "  rmse_scores = np.sqrt(-1 * neg_mse_scores)\n",
        "  avg_rmse = np.mean(rmse_scores)\n",
        "  model.fit(X_data, y_target)\n",
        "  score = model.score(X_data, y_target)\n",
        "  kf_cv_scores = cross_val_score(model, X_data, y_target)\n",
        "  print('#### ', model.__class__.__name__, ' ####')\n",
        "  print(' 5 교차 검증의 평균 RMSE : {0:.3f} '.format(avg_rmse))\n",
        "  print('score : ', score)\n",
        "  print(\"K-fold CV scores : {}\" .format(kf_cv_scores))\n",
        "  print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZtNys6DmXb0"
      },
      "source": [
        "## XGBoost Regressor 하이퍼파라미터\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7YJNa5omXb0"
      },
      "source": [
        "# XGBoost Hypter Parameter Tuning\n",
        "def XGBhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.03, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'min_child_weight': [1, 3, 5],\n",
        "        'subsample': [0.5, 0.7],\n",
        "        'colsample_bytree': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500],\n",
        "        'objective': ['reg:squarederror'],\n",
        "        'gamma' : [0.1, 0.2, 0.3, 0.4],\n",
        "\n",
        "    }\n",
        "\n",
        "    xgb_model = XGBRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = xgb_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def RFRhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 1000],\n",
        "    \n",
        "    }\n",
        "\n",
        "    rf_model = RandomForestRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = rf_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def LGBMhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.03, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'min_child_samples' : [10, 20, 30],\n",
        "        'subsample' : [0.5, 0.7],\n",
        "        'colsample_bytree': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500],\n",
        "        'objective': ['regression'],\n",
        "        'gamma' : [0.1, 0.2, 0.3],\n",
        "        'num_leaves' : [6, 8, 10]\n",
        "\n",
        "    }\n",
        "\n",
        "    lgbm = LGBMRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = lgbm,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def GBRhyperParameterTuning(X_train, y_train):\n",
        "    \n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'subsample': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500]\n",
        "\n",
        "    }\n",
        "\n",
        "    gb_model = GradientBoostingRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = gb_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcSpB-krmXb0"
      },
      "source": [
        "xgb_parameter = XGBhyperParameterTuning(X_train, y_train)\n",
        "xgb_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYni3tK5mXb0"
      },
      "source": [
        "rf_parameter = RFRhyperParameterTuning(X_train, y_train)\n",
        "rf_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8COGk46mXb0"
      },
      "source": [
        "lgbm_parameter = LGBMhyperParameterTuning(X_train, y_train)\n",
        "lgbm_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGr98vGymXb0"
      },
      "source": [
        "\n",
        "#rf_parameter = RFRhyperParameterTuning(X_train, y_train)\n",
        "#rf_parameter\n",
        "\n",
        "gbr_parameter= GBRhyperParameterTuning(X_train, y_train)\n",
        "gbr_parameter\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh--QBUJmXb1"
      },
      "source": [
        "# 모델 생성 및 예측\n",
        "xgb_reg = XGBRegressor(colsample_bytree = 0.7, \n",
        "                       gamma = 0.2,\n",
        "                       learning_rate = 0.1,\n",
        "                       max_depth = 5,\n",
        "                       min_child_weight = 1,\n",
        "                       n_estimators = 500,\n",
        "                       objective = 'reg:squarederror',\n",
        "                       subsample = 0.7)\n",
        "\n",
        "rf_reg = RandomForestRegressor(random_state=0, \n",
        "                               bootstrap = [True],\n",
        "                               max_depth = 10,\n",
        "                               max_features = 3,\n",
        "                               min_samples_leaf = 3,\n",
        "                               min_samples_split = 8,\n",
        "                               n_estimators = 100\n",
        "                               )\n",
        "\n",
        "lgb_reg = LGBMRegressor(colsample_bytree = 0.7,\n",
        "                        gamma = 0.1,\n",
        "                        learning_rate = 0.03,\n",
        "                        max_depth = 7,\n",
        "                        min_child_samples = 10,\n",
        "                        n_estimators = 200,\n",
        "                        num_leaves =8,\n",
        "                        objective = 'regression',\n",
        "                        subsample = 0.5)\n",
        "\n",
        "gb_reg = GradientBoostingRegressor(random_state=0, \n",
        "                                   learning_rate=0.1,\n",
        "                                   max_depth=3,\n",
        "                                   n_estimators=200,\n",
        "                                   subsample=0.5\n",
        "                                   )\n",
        "\n",
        "models = [lgb_reg, rf_reg, gb_reg, xgb_reg, lgb_reg]\n",
        "\n",
        "for model in models:\n",
        "  get_model_cv_prediction(model, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzmGSppXmXb1"
      },
      "source": [
        "ypred = rf_reg.predict(X_test)\n",
        "mse = mean_squared_error(y_test, ypred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKo7f3xXmXb1"
      },
      "source": [
        "x_ax = range(len(y_test))\n",
        "plt.plot(x_ax, y_test, label=\"Original Price\")\n",
        "plt.plot(x_ax, ypred, label=\"Predicted Price\")\n",
        "plt.title(\"Price Prediction\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKBJoiU3mXb1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SdvWYbjmXb1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM_h_b4jmXb1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JVL5Hs6mXb1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kppA_WKAr_Tm"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwuipB0vIkg1"
      },
      "source": [
        "#배추"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8V3Mgndss9iT"
      },
      "source": [
        "dataset = pd.read_excel('/content/배추_시장.xlsx')\n",
        "# dataset = pd.merge(dataset, wholesale, how='left', on='일자' )\n",
        "# dataset.head()\n",
        "# dataset = pd.read_excel('/content/무_특_반입_경락_시장_날씨_Holy_유가.xlsx')\n",
        "# dataset = dataset.drop(['일자','품목명','품목코드','유무','평균 5cm 지중온도(°C)','평균 지면온도(°C)','최고기온(°C)','합계 일조시간(hr)','최저기온(°C)'], axis=1)\n",
        "# dataset = dataset.drop(['일자', '최대 풍속(m/s)',\t'평균 풍속(m/s)',\t'평균 상대습도(%)',\t'합계 일조시간(hr)',\t'평균 지면온도(°C)',\t'평균 5cm 지중온도(°C)', '여부'], axis=1)\n",
        "# dataset = dataset[['도매가격', '100g가격', '유가 전국평균가격', '평균 풍속(m/s)', '여부', '최고기온(°C)', '평균 지면온도(°C)', '평균 5cm 지중온도(°C)', '일강수량(mm)', '반입량']]\n",
        "# dataset = dataset.drop(['일자','Unnamed: 0'], axis=1)\n",
        "#dataset = dataset.drop(['일자'], axis=1)\n",
        "dataset = dataset.dropna()\n",
        "dataset.head()\n",
        "# dataset.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zw4AABkdK8qO"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCvv_BRjtGan"
      },
      "source": [
        "y_target = dataset['가격']\n",
        "X_data = dataset.drop(['가격'], axis=1, inplace=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyeZE--HtHWl"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_target, test_size=0.15, random_state=140)\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh77Y8bXtNQW"
      },
      "source": [
        "# 검증해주는 함수\n",
        "def get_model_cv_prediction(model, X_data, y_target):\n",
        "  neg_mse_scores=cross_val_score(model, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 5)\n",
        "  rmse_scores = np.sqrt(-1 * neg_mse_scores)\n",
        "  avg_rmse = np.mean(rmse_scores)\n",
        "  model.fit(X_data, y_target)\n",
        "  score = model.score(X_data, y_target)\n",
        "  kf_cv_scores = cross_val_score(model, X_data, y_target)\n",
        "  print('#### ', model.__class__.__name__, ' ####')\n",
        "  print(' 5 교차 검증의 평균 RMSE : {0:.3f} '.format(avg_rmse))\n",
        "  print('score : ', score)\n",
        "  print(\"K-fold CV scores : {}\" .format(kf_cv_scores))\n",
        "  print(\"K-fold CV average score: %.2f\" % kf_cv_scores.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ital2WhZgAh0"
      },
      "source": [
        "## XGBoost Regressor 하이퍼파라미터\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ql8ToBz_gP3i"
      },
      "source": [
        "# XGBoost Hypter Parameter Tuning\n",
        "def XGBhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.03, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'min_child_weight': [1, 3, 5],\n",
        "        'subsample': [0.5, 0.7],\n",
        "        'colsample_bytree': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500],\n",
        "        'objective': ['reg:squarederror'],\n",
        "        'gamma' : [0.1, 0.2, 0.3, 0.4],\n",
        "\n",
        "    }\n",
        "\n",
        "    xgb_model = XGBRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = xgb_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def RFRhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 4, 5],\n",
        "    'min_samples_split': [8, 10, 12],\n",
        "    'n_estimators': [100, 200, 300, 1000],\n",
        "    \n",
        "    }\n",
        "\n",
        "    rf_model = RandomForestRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = rf_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def LGBMhyperParameterTuning(X_train, y_train):\n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.03, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'min_child_samples' : [10, 20, 30],\n",
        "        'subsample' : [0.5, 0.7],\n",
        "        'colsample_bytree': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500],\n",
        "        'objective': ['regression'],\n",
        "        'gamma' : [0.1, 0.2, 0.3],\n",
        "        'num_leaves' : [6, 8, 10]\n",
        "\n",
        "    }\n",
        "\n",
        "    lgbm = LGBMRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = lgbm,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_\n",
        "\n",
        "def GBRhyperParameterTuning(X_train, y_train):\n",
        "    \n",
        "    param_tuning = {\n",
        "        'learning_rate': [0.01, 0.05, 0.1],\n",
        "        'max_depth': [3, 5, 7, 10],\n",
        "        'subsample': [0.5, 0.7],\n",
        "        'n_estimators' : [100, 200, 500]\n",
        "\n",
        "    }\n",
        "\n",
        "    gb_model = GradientBoostingRegressor()\n",
        "\n",
        "    gsearch = GridSearchCV(estimator = gb_model,\n",
        "                           param_grid = param_tuning,                        \n",
        "                           #scoring = 'neg_mean_absolute_error', #MAE\n",
        "                           #scoring = 'neg_mean_squared_error',  #MSE\n",
        "                           cv = 3,\n",
        "                           n_jobs = -1,\n",
        "                           verbose = 1)\n",
        "\n",
        "    gsearch.fit(X_train,y_train)\n",
        "\n",
        "    return gsearch.best_params_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S11ES3a40jX"
      },
      "source": [
        "xgb_parameter = XGBhyperParameterTuning(X_train, y_train)\n",
        "xgb_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4S0k-S5B40sa"
      },
      "source": [
        "rf_parameter = RFRhyperParameterTuning(X_train, y_train)\n",
        "rf_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN4Gz1kf40y9"
      },
      "source": [
        "lgbm_parameter = LGBMhyperParameterTuning(X_train, y_train)\n",
        "lgbm_parameter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0yX6PRhq8Vg"
      },
      "source": [
        "\n",
        "#rf_parameter = RFRhyperParameterTuning(X_train, y_train)\n",
        "#rf_parameter\n",
        "\n",
        "gbr_parameter= GBRhyperParameterTuning(X_train, y_train)\n",
        "gbr_parameter\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTFOYkPFuH-n"
      },
      "source": [
        "# 모델 생성 및 예측\n",
        "xgb_reg = XGBRegressor(colsample_bytree = 0.7, \n",
        "                       gamma = 0.2,\n",
        "                       learning_rate = 0.1,\n",
        "                       max_depth = 5,\n",
        "                       min_child_weight = 1,\n",
        "                       n_estimators = 500,\n",
        "                       objective = 'reg:squarederror',\n",
        "                       subsample = 0.7)\n",
        "\n",
        "rf_reg = RandomForestRegressor(random_state=0, \n",
        "                               bootstrap = [True],\n",
        "                               max_depth = 10,\n",
        "                               max_features = 3,\n",
        "                               min_samples_leaf = 3,\n",
        "                               min_samples_split = 8,\n",
        "                               n_estimators = 100\n",
        "                               )\n",
        "\n",
        "lgb_reg = LGBMRegressor(colsample_bytree = 0.7,\n",
        "                        gamma = 0.1,\n",
        "                        learning_rate = 0.03,\n",
        "                        max_depth = 7,\n",
        "                        min_child_samples = 10,\n",
        "                        n_estimators = 200,\n",
        "                        num_leaves =8,\n",
        "                        objective = 'regression',\n",
        "                        subsample = 0.5)\n",
        "\n",
        "gb_reg = GradientBoostingRegressor(random_state=0, \n",
        "                                   learning_rate=0.1,\n",
        "                                   max_depth=3,\n",
        "                                   n_estimators=200,\n",
        "                                   subsample=0.5\n",
        "                                   )\n",
        "\n",
        "models = [lgb_reg, rf_reg, gb_reg, xgb_reg, lgb_reg]\n",
        "\n",
        "for model in models:\n",
        "  get_model_cv_prediction(model, X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2GAHHKpuIA-"
      },
      "source": [
        "ypred = rf_reg.predict(X_test)\n",
        "mse = mean_squared_error(y_test, ypred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTja4A6yuIDD"
      },
      "source": [
        "x_ax = range(len(y_test))\n",
        "plt.plot(x_ax, y_test, label=\"Original Price\")\n",
        "plt.plot(x_ax, ypred, label=\"Predicted Price\")\n",
        "plt.title(\"Price Prediction\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLwaHJIyuIE9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaxrslxBuRcV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtpJ8UqyuRej"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkoskiPhuRg0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}