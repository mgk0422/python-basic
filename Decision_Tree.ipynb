{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Decision Tree",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNfDOW6vcs4nFUfqKZB3THs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgk0422/python-basic/blob/master/Decision_Tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF_gJ_iUKUJn"
      },
      "source": [
        "# 결정트리 : 데이터에 있는 규칙을 학습을 통해 자동으로 찾아내 트리(Tree) 기반의 분류 규칙을 만드는 것\r\n",
        "# 트리의 깊이가 깊어질수록 결정 트리의 예측 성능이 저하될 가능성이 있음.\r\n",
        "# 규칙노드 : 규칙 조건\r\n",
        "# 리프노드 : 결정된 클래스 값\r\n",
        "# 새로운 규칙마다 서브트리가 생성"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8WSpvtlLJX6"
      },
      "source": [
        "# 정보의 균일도를 측정하는 대표적인 방법 : 정보이득 지수와 지니계수\r\n",
        "# 정보이득은 엔트로피라는 개념을 기반으로함\r\n",
        "# 엔트로피 : 주어진 데이터 집합의 혼잡도를 의미 // 서로 다른 값이 섞여있으면 엔트로피가 높고, 같은 값이 섞여있으면 엔트로피값이 낮음\r\n",
        "# 정보이득지수 = 1 - 엔트로피\r\n",
        "# 결정트리는 정보이득 지수로 분할을 정함, 정보 이득이 높은 속성을 기준으로 분할"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e22GGwcvMEzi"
      },
      "source": [
        "# 결정트리의 장점 정보의 균일도라는 룰을 기반으로 하고 있어 알고리즘이 쉽고 직관적이다. 시각화(Graphviz)로 표현 가능, 특별한 경우 제외하고 각 피처의 스케일링과 정규화 같은 전처리 작업이 필요 없음\r\n",
        "# 단점 .... 과적합으로 정확도가 떨어짐\r\n",
        "# 트리의 크기를 제한하는 것이 오히려 성능 튜닝에 도움이된다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kkehFujM9OV"
      },
      "source": [
        "pip install graphviz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVi1DjpOP8Y1"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.datasets import load_iris\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "\r\n",
        "#DecisionTree Classifier생성\r\n",
        "dt_clf=DecisionTreeClassifier(random_state=156)\r\n",
        "\r\n",
        "iris_data=load_iris()\r\n",
        "X_train,X_test,y_train,y_test=train_test_split(iris_data.data,iris_data.target,test_size=0.2,random_state=11)\r\n",
        "\r\n",
        "dt_clf.fit(X_train,y_train)\r\n",
        "\r\n",
        "from sklearn.tree import export_graphviz\r\n",
        "\r\n",
        "export_graphviz(dt_clf,out_file='tree.dot',class_names=iris_data.target_names,feature_names=iris_data.feature_names,impurity=True,filled=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVUVNSMnRMIw"
      },
      "source": [
        "import graphviz\r\n",
        "\r\n",
        "with open(\"tree.dot\") as f:\r\n",
        "    dot_graph=f.read()\r\n",
        "graphviz.Source(dot_graph)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdxDOX3ORzj3"
      },
      "source": [
        "# 1번 노드 지표 설명 samples=120 전체 데이터가 120개이다\r\n",
        "# value=[41,40,39]는 Setosa 41개 , Versicolor 40개 , Virginica 39개로 구성\r\n",
        "# 지니계수 0.667\r\n",
        "\r\n",
        "# feature_importances 속성을 가져와 피처별로 중요도 값"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxEyAOZPSvqL"
      },
      "source": [
        "import seaborn as sns\r\n",
        "import numpy as np\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "# feature importance 추출\r\n",
        "print('feature importance :\\n{0}',format(np.round(dt_clf.feature_importances_,4)))\r\n",
        "\r\n",
        "# feature importance 매핑\r\n",
        "for name,value in zip(iris_data.feature_names,dt_clf.feature_importances_):\r\n",
        "    print('{0}:{1:.3f}'.format(name,value))\r\n",
        "\r\n",
        "# feature importance를 column 별로 시각화하기\r\n",
        "sns.barplot(x=dt_clf.feature_importances_,y=iris_data.feature_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uj3W89-VTe33"
      },
      "source": [
        "# 결정트리 과적합(Overfitting)\r\n",
        "\r\n",
        "from sklearn.datasets import make_classification\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "X_features,y_labels=make_classification(n_features=2,n_redundant=0,n_informative=2,n_classes=3,n_clusters_per_class=1,random_state=0)\r\n",
        "\r\n",
        "plt.scatter(X_features[:,0],X_features[:,1],marker='o',c=y_labels,s=25,edgecolor='k')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5NF4VqGUxr0"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "#특정한 트리 생성 제약 없는 결정 트리의 학습과 결정 경계 시각화.\r\n",
        "dt_clf=DecisionTreeClassifier().fit(X_features,y_labels)\r\n",
        "#isualize_boundary(dt_clf,X_features,y_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mkNdJdCVafb"
      },
      "source": [
        "#min_sample_leaf=6으로 트리 생성 조건을 제약한 결정 경계 시각화\r\n",
        "dt_clf=DecisionTreeClassifier(min_samples_leaf=6).fit(X_features,y_labels)\r\n",
        "visualize_boundary(dt_clf,X_features,y_labels)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}